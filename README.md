# WorldOMeter-Data-Storage
WScraping- Python - GSheets - PowerBI
This is a project I've been working on during the past few days. It is supposed to store data from the website WorldOMeter every 6 hours. After a year, I plan on doing some type of time series analysis on this, however, for the meantime, the data will be available daily on PowerBI, being automatically taken from the web and published for anyone to see. Some graphs will be available, allowing anyone to see how the total population, suicide rates, CO2 emissions, have been increasing daily, weekly, monthly, or every 6 hours. Besides this, it'll be possible to see during which days of the week each of these statistics tend to increase or decrease faster.
The project was made using the windows task scheduler to execute an .exe Python file created using the lybrary pyinstaller. The jupyter .ipynb file will be available here, and it'll be possible to see what I've done to be able to extract data from the website (Library Selenium) and store it on a Google Sheets spreadsheet, on 3 different worksheets (Library GSpread). After this, I will do some data manipulation on PowerBI, including a bit of data which hasn't yet been included on Python due to the amount of requests that would be necessary for the Google API in order to be able to store this data on Google Sheets, and then schedule the dashboard to always be published 1 hour after the data has been extracted. 
